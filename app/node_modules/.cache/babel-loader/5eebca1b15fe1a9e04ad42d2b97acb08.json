{"ast":null,"code":"'use strict';\n\nmodule.exports = text;\n\nfunction text(eat, value, silent) {\n  var self = this;\n  var methods;\n  var tokenizers;\n  var index;\n  var length;\n  var subvalue;\n  var position;\n  var tokenizer;\n  var name;\n  var min;\n  var now;\n  /* istanbul ignore if - never used (yet) */\n\n  if (silent) {\n    return true;\n  }\n\n  methods = self.inlineMethods;\n  length = methods.length;\n  tokenizers = self.inlineTokenizers;\n  index = -1;\n  min = value.length;\n\n  while (++index < length) {\n    name = methods[index];\n\n    if (name === 'text' || !tokenizers[name]) {\n      continue;\n    }\n\n    tokenizer = tokenizers[name].locator;\n\n    if (!tokenizer) {\n      eat.file.fail('Missing locator: `' + name + '`');\n    }\n\n    position = tokenizer.call(self, value, 1);\n\n    if (position !== -1 && position < min) {\n      min = position;\n    }\n  }\n\n  subvalue = value.slice(0, min);\n  now = eat.now();\n  self.decode(subvalue, now, handler);\n\n  function handler(content, position, source) {\n    eat(source || content)({\n      type: 'text',\n      value: content\n    });\n  }\n}","map":{"version":3,"names":["module","exports","text","eat","value","silent","self","methods","tokenizers","index","length","subvalue","position","tokenizer","name","min","now","inlineMethods","inlineTokenizers","locator","file","fail","call","slice","decode","handler","content","source","type"],"sources":["/Users/The5AMDev/web3/gif-portal-starter/node_modules/remark-parse/lib/tokenize/text.js"],"sourcesContent":["'use strict'\n\nmodule.exports = text\n\nfunction text(eat, value, silent) {\n  var self = this\n  var methods\n  var tokenizers\n  var index\n  var length\n  var subvalue\n  var position\n  var tokenizer\n  var name\n  var min\n  var now\n\n  /* istanbul ignore if - never used (yet) */\n  if (silent) {\n    return true\n  }\n\n  methods = self.inlineMethods\n  length = methods.length\n  tokenizers = self.inlineTokenizers\n  index = -1\n  min = value.length\n\n  while (++index < length) {\n    name = methods[index]\n\n    if (name === 'text' || !tokenizers[name]) {\n      continue\n    }\n\n    tokenizer = tokenizers[name].locator\n\n    if (!tokenizer) {\n      eat.file.fail('Missing locator: `' + name + '`')\n    }\n\n    position = tokenizer.call(self, value, 1)\n\n    if (position !== -1 && position < min) {\n      min = position\n    }\n  }\n\n  subvalue = value.slice(0, min)\n  now = eat.now()\n\n  self.decode(subvalue, now, handler)\n\n  function handler(content, position, source) {\n    eat(source || content)({type: 'text', value: content})\n  }\n}\n"],"mappings":"AAAA;;AAEAA,MAAM,CAACC,OAAP,GAAiBC,IAAjB;;AAEA,SAASA,IAAT,CAAcC,GAAd,EAAmBC,KAAnB,EAA0BC,MAA1B,EAAkC;EAChC,IAAIC,IAAI,GAAG,IAAX;EACA,IAAIC,OAAJ;EACA,IAAIC,UAAJ;EACA,IAAIC,KAAJ;EACA,IAAIC,MAAJ;EACA,IAAIC,QAAJ;EACA,IAAIC,QAAJ;EACA,IAAIC,SAAJ;EACA,IAAIC,IAAJ;EACA,IAAIC,GAAJ;EACA,IAAIC,GAAJ;EAEA;;EACA,IAAIX,MAAJ,EAAY;IACV,OAAO,IAAP;EACD;;EAEDE,OAAO,GAAGD,IAAI,CAACW,aAAf;EACAP,MAAM,GAAGH,OAAO,CAACG,MAAjB;EACAF,UAAU,GAAGF,IAAI,CAACY,gBAAlB;EACAT,KAAK,GAAG,CAAC,CAAT;EACAM,GAAG,GAAGX,KAAK,CAACM,MAAZ;;EAEA,OAAO,EAAED,KAAF,GAAUC,MAAjB,EAAyB;IACvBI,IAAI,GAAGP,OAAO,CAACE,KAAD,CAAd;;IAEA,IAAIK,IAAI,KAAK,MAAT,IAAmB,CAACN,UAAU,CAACM,IAAD,CAAlC,EAA0C;MACxC;IACD;;IAEDD,SAAS,GAAGL,UAAU,CAACM,IAAD,CAAV,CAAiBK,OAA7B;;IAEA,IAAI,CAACN,SAAL,EAAgB;MACdV,GAAG,CAACiB,IAAJ,CAASC,IAAT,CAAc,uBAAuBP,IAAvB,GAA8B,GAA5C;IACD;;IAEDF,QAAQ,GAAGC,SAAS,CAACS,IAAV,CAAehB,IAAf,EAAqBF,KAArB,EAA4B,CAA5B,CAAX;;IAEA,IAAIQ,QAAQ,KAAK,CAAC,CAAd,IAAmBA,QAAQ,GAAGG,GAAlC,EAAuC;MACrCA,GAAG,GAAGH,QAAN;IACD;EACF;;EAEDD,QAAQ,GAAGP,KAAK,CAACmB,KAAN,CAAY,CAAZ,EAAeR,GAAf,CAAX;EACAC,GAAG,GAAGb,GAAG,CAACa,GAAJ,EAAN;EAEAV,IAAI,CAACkB,MAAL,CAAYb,QAAZ,EAAsBK,GAAtB,EAA2BS,OAA3B;;EAEA,SAASA,OAAT,CAAiBC,OAAjB,EAA0Bd,QAA1B,EAAoCe,MAApC,EAA4C;IAC1CxB,GAAG,CAACwB,MAAM,IAAID,OAAX,CAAH,CAAuB;MAACE,IAAI,EAAE,MAAP;MAAexB,KAAK,EAAEsB;IAAtB,CAAvB;EACD;AACF"},"metadata":{},"sourceType":"script"}